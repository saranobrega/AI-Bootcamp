{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BHWKD5MdpL-s"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tg7FU1IOp8sr"
   },
   "source": [
    "# Common AI models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HdgY22i6qVUB"
   },
   "source": [
    "# Classic machine learning models\n",
    "\n",
    "## Assignment 1\n",
    "From the Sklearn library choose models of at least the following types, train them on the 6 imported datasets, evaluate their accuracy or R^2 and see which model works best on which dataset. (Note that there are both regression and classification sets)\n",
    "* Tree\n",
    "* Neural Network\n",
    "* Neighbors\n",
    "* Ensemble\n",
    "* Naive Byes (classification only)\n",
    "* Linear\n",
    "\n",
    "## Assignment 2\n",
    "Use XGBoost running on GPU to predict the same datasets. You can activate GPU acceleration in the Runtime tab:\n",
    "Runtime -> Change runtime type -> Select GPU from the dropdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yUNtA_LMp877"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris, load_boston, load_diabetes, load_digits, load_wine, load_breast_cancer\n",
    "from sklearn.metrics import accuracy_score, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Example of how to load \n",
    "X = load_iris().data\n",
    "y = load_iris().target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2hj-NtXkp8_a",
    "outputId": "19de2505-3dd4-4e95-e354-58dfaecfaeff"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neural_network.multilayer_perceptron module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neural_network. Anything that cannot be imported from sklearn.neural_network is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_iris\n",
      "DecisionTreeClassifier accuracy:  0.98\n",
      "MLPClassifier accuracy:  1.0\n",
      "KNeighborsClassifier accuracy:  0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier accuracy:  0.98\n",
      "GaussianNB accuracy:  0.96\n",
      "LinearSVC accuracy:  0.98\n",
      "LogisticRegression accuracy:  1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier accuracy:  0.98\n",
      "load_boston\n",
      "DecisionTreeRegressor accuracy:  0.7514129834828985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor accuracy:  0.615450665222141\n",
      "KNeighborsRegressor accuracy:  0.5748334691810936\n",
      "RandomForestRegressor accuracy:  0.8627218878397265\n",
      "LinearSVR accuracy:  0.30126863175216845\n",
      "LinearRegression accuracy:  0.7261570836552481\n",
      "[08:03:26] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor accuracy:  0.8906424514798732\n",
      "load_diabetes\n",
      "DecisionTreeRegressor accuracy:  -0.15202062095000368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor accuracy:  -3.086784987506947\n",
      "KNeighborsRegressor accuracy:  0.43975256620686554\n",
      "RandomForestRegressor accuracy:  0.47198314771902505\n",
      "LinearSVR accuracy:  -0.42343950619158965\n",
      "LinearRegression accuracy:  0.510395426135144\n",
      "[08:03:27] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "XGBRegressor accuracy:  0.4297231468315629\n",
      "load_digits\n",
      "DecisionTreeClassifier accuracy:  0.8333333333333334\n",
      "MLPClassifier accuracy:  0.9747474747474747\n",
      "KNeighborsClassifier accuracy:  0.9932659932659933\n",
      "RandomForestClassifier accuracy:  0.9747474747474747\n",
      "GaussianNB accuracy:  0.8164983164983165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC accuracy:  0.9444444444444444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression accuracy:  0.9629629629629629\n",
      "XGBClassifier accuracy:  0.9646464646464646\n",
      "load_wine\n",
      "DecisionTreeClassifier accuracy:  0.9491525423728814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier accuracy:  0.8813559322033898\n",
      "KNeighborsClassifier accuracy:  0.6779661016949152\n",
      "RandomForestClassifier accuracy:  1.0\n",
      "GaussianNB accuracy:  1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC accuracy:  0.9152542372881356\n",
      "LogisticRegression accuracy:  0.9830508474576272\n",
      "XGBClassifier accuracy:  0.9830508474576272\n",
      "load_breast_cancer\n",
      "DecisionTreeRegressor accuracy:  0.6985321327248057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor accuracy:  -3.7012407086130654\n",
      "KNeighborsRegressor accuracy:  0.8497298630812877\n",
      "RandomForestRegressor accuracy:  0.8405629209325274\n",
      "LinearSVR accuracy:  0.31458587908767177\n",
      "LinearRegression accuracy:  0.6911359869475926\n",
      "[08:03:43] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor accuracy:  0.8301625511124916\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "#from sklearn.svm.classes import OneClassSVM\n",
    "from sklearn.neural_network.multilayer_perceptron import MLPClassifier, MLPRegressor\n",
    "#from sklearn.neighbors.classification import RadiusNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "#from sklearn.multioutput import ClassifierChain\n",
    "#from sklearn.multioutput import MultiOutputClassifier\n",
    "#from sklearn.multiclass import OutputCodeClassifier\n",
    "#from sklearn.multiclass import OneVsOneClassifier\n",
    "#from sklearn.multiclass import OneVsRestClassifier\n",
    "#from sklearn.linear_model.stochastic_gradient import SGDClassifier\n",
    "#from sklearn.linear_model.ridge import RidgeClassifierCV\n",
    "#from sklearn.linear_model.ridge import RidgeClassifier\n",
    "#from sklearn.linear_model.passive_aggressive import PassiveAggressiveClassifier    \n",
    "#from sklearn.gaussian_process.gpc import GaussianProcessClassifier\n",
    "#from sklearn.ensemble.voting_classifier import VotingClassifier\n",
    "#from sklearn.ensemble.weight_boosting import AdaBoostClassifier\n",
    "#from sklearn.ensemble.gradient_boosting import GradientBoostingClassifier\n",
    "#from sklearn.ensemble.bagging import BaggingClassifier\n",
    "#from sklearn.ensemble.forest import ExtraTreesClassifier\n",
    "from sklearn.ensemble.forest import RandomForestClassifier, RandomForestRegressor\n",
    "#from sklearn.naive_bayes import BernoulliNB\n",
    "#from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "#from sklearn.semi_supervised import LabelPropagation\n",
    "#from sklearn.semi_supervised import LabelSpreading\n",
    "#from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import LinearSVC, LinearSVR\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "#from sklearn.linear_model import LogisticRegressionCV\n",
    "#from sklearn.naive_bayes import MultinomialNB  \n",
    "#from sklearn.neighbors import NearestCentroid\n",
    "#from sklearn.svm import NuSVC\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "\n",
    "classifiers = [DecisionTreeClassifier, MLPClassifier, KNeighborsClassifier, RandomForestClassifier, GaussianNB, LinearSVC, LogisticRegression, XGBClassifier]\n",
    "regressors = [DecisionTreeRegressor, MLPRegressor, KNeighborsRegressor, RandomForestRegressor, LinearSVR, LinearRegression, XGBRegressor]\n",
    "\n",
    "results = {}\n",
    "\n",
    "data_loaders = [load_iris, load_boston, load_diabetes, load_digits, load_wine, load_breast_cancer]\n",
    "for loader in data_loaders:\n",
    "    loader_name = loader.__name__\n",
    "    print(loader_name)\n",
    "    results[loader_name] = {}\n",
    "    X = loader().data\n",
    "    y = loader().target\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "    if 'Classification' in loader().DESCR:\n",
    "        models = classifiers\n",
    "    else:\n",
    "        models = regressors\n",
    "\n",
    "    for m in models:\n",
    "        model_name = m.__name__\n",
    "        drop = {}\n",
    "\n",
    "        if \"XGB\" in model_name:\n",
    "            m = m(tree_method='gpu_hist')\n",
    "        else:\n",
    "            m = m()\n",
    "        fitted = m.fit(X=X_train, y=y_train)\n",
    "\n",
    "        y_pred = fitted.predict(X_test)\n",
    "\n",
    "        if 'Classification' in loader().DESCR:\n",
    "            score = accuracy_score(y_test, y_pred)\n",
    "        else: \n",
    "            score = r2_score(y_test, y_pred)\n",
    "\n",
    "        results[loader_name][model_name]['score'] = score\n",
    "        print(f'{model_name} accuracy: ', score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "owaINkqJOfwp",
    "outputId": "56b27ab4-87b0-46a8-a1a5-d0a77eec31b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model on load_iris was MLPClassifier with score: 1.0\n",
      "Best model on load_boston was XGBRegressor with score: 0.8906424514798732\n",
      "Best model on load_diabetes was LinearRegression with score: 0.510395426135144\n",
      "Best model on load_digits was KNeighborsClassifier with score: 0.9932659932659933\n",
      "Best model on load_wine was RandomForestClassifier with score: 1.0\n",
      "Best model on load_breast_cancer was KNeighborsRegressor with score: 0.8497298630812877\n"
     ]
    }
   ],
   "source": [
    "for k, v in results.items():\n",
    "    best_model = ''\n",
    "    highest_score = -999\n",
    "    for a, b, in v.items():\n",
    "        if b['score'] > highest_score:\n",
    "            best_model = a\n",
    "            highest_score = b['score']\n",
    "    print(f'Best model on {k} was {best_model} with score: {highest_score}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QKgpKCj5Hpal",
    "outputId": "d3e5483f-82a5-407c-b6de-e6aae1809158"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'load_boston': {'DecisionTreeRegressor': {'score': 0.7514129834828985},\n",
       "  'KNeighborsRegressor': {'score': 0.5748334691810936},\n",
       "  'LinearRegression': {'score': 0.7261570836552481},\n",
       "  'LinearSVR': {'score': 0.30126863175216845},\n",
       "  'MLPRegressor': {'score': 0.615450665222141},\n",
       "  'RandomForestRegressor': {'score': 0.8627218878397265},\n",
       "  'XGBRegressor': {'score': 0.8906424514798732}},\n",
       " 'load_breast_cancer': {'DecisionTreeRegressor': {'score': 0.6985321327248057},\n",
       "  'KNeighborsRegressor': {'score': 0.8497298630812877},\n",
       "  'LinearRegression': {'score': 0.6911359869475926},\n",
       "  'LinearSVR': {'score': 0.31458587908767177},\n",
       "  'MLPRegressor': {'score': -3.7012407086130654},\n",
       "  'RandomForestRegressor': {'score': 0.8405629209325274},\n",
       "  'XGBRegressor': {'score': 0.8301625511124916}},\n",
       " 'load_diabetes': {'DecisionTreeRegressor': {'score': -0.15202062095000368},\n",
       "  'KNeighborsRegressor': {'score': 0.43975256620686554},\n",
       "  'LinearRegression': {'score': 0.510395426135144},\n",
       "  'LinearSVR': {'score': -0.42343950619158965},\n",
       "  'MLPRegressor': {'score': -3.086784987506947},\n",
       "  'RandomForestRegressor': {'score': 0.47198314771902505},\n",
       "  'XGBRegressor': {'score': 0.4297231468315629}},\n",
       " 'load_digits': {'DecisionTreeClassifier': {'score': 0.8333333333333334},\n",
       "  'GaussianNB': {'score': 0.8164983164983165},\n",
       "  'KNeighborsClassifier': {'score': 0.9932659932659933},\n",
       "  'LinearSVC': {'score': 0.9444444444444444},\n",
       "  'LogisticRegression': {'score': 0.9629629629629629},\n",
       "  'MLPClassifier': {'score': 0.9747474747474747},\n",
       "  'RandomForestClassifier': {'score': 0.9747474747474747},\n",
       "  'XGBClassifier': {'score': 0.9646464646464646}},\n",
       " 'load_iris': {'DecisionTreeClassifier': {'score': 0.98},\n",
       "  'GaussianNB': {'score': 0.96},\n",
       "  'KNeighborsClassifier': {'score': 0.98},\n",
       "  'LinearSVC': {'score': 0.98},\n",
       "  'LogisticRegression': {'score': 1.0},\n",
       "  'MLPClassifier': {'score': 1.0},\n",
       "  'RandomForestClassifier': {'score': 0.98},\n",
       "  'XGBClassifier': {'score': 0.98}},\n",
       " 'load_wine': {'DecisionTreeClassifier': {'score': 0.9491525423728814},\n",
       "  'GaussianNB': {'score': 1.0},\n",
       "  'KNeighborsClassifier': {'score': 0.6779661016949152},\n",
       "  'LinearSVC': {'score': 0.9152542372881356},\n",
       "  'LogisticRegression': {'score': 0.9830508474576272},\n",
       "  'MLPClassifier': {'score': 0.8813559322033898},\n",
       "  'RandomForestClassifier': {'score': 1.0},\n",
       "  'XGBClassifier': {'score': 0.9830508474576272}}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SPriRhw0RvPs"
   },
   "source": [
    "## Neural Nets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6eLXHx8LuNsi"
   },
   "source": [
    "The moment you have all been waiting for, let's finally build our own neural network architecture! While you have already used Neural Nets in the previous assignment when using the Multi-Layer Perceptron (MLP), you did not really define an architecture. MLPs are generally a stack of fully connected a.k.a. Dense layers and that is what we will start with here as well. We will use one of the previous datasets and optimize the architecture below to improve the test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5nDFkGF2nRlI",
    "outputId": "f7182ab9-13fc-41f2-e189-86dc5df9392c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "loader = load_iris()\n",
    "X = loader.data\n",
    "y = loader.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MAzmm2EEyztR"
   },
   "source": [
    "### Encode the target data\n",
    "When doing a classification using NNs we generally one-hot encode the target variable. One-hot encoding meaning that we convert the target label into a binary vector where the length of the vector is the same size as the number of categories and we encode a class by keeping all scalars in the vector 0 except for the class that we want to encode which is 1. In other words, only one of the 10 values in the array can be 1 while all others are 0 and the location of the 1 represents the number in the class. so 4 becomes [0,0,0,1,0,0,0,0,0,0]\n",
    "\n",
    "We sadly do not have time to go into detail on why this is and how you should go about this. SKlearn's LaberBinarizer below will do the trick for you. For those that are curious, you encode classes in an array because when you use a single number the neural network will assume that class 1 is closer to class 2 than to class 7. Think of it as classifying pictures of animals, the networks would think that class 1 (dog) is closer to class 2 (horse) than to class 8 (cat).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iWQZTl0Aoty6",
    "outputId": "7169f125-8200-4a51-d8b2-58eaa6b6ac96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Convert labels to onehot encoding\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "lb = LabelBinarizer()\n",
    "lb.fit(y_train)\n",
    "y_train = lb.transform(y_train)\n",
    "y_test = lb.transform(y_test)\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6KgwMxMYzaZ_"
   },
   "source": [
    "### Designing the Neural Network\n",
    "Designing an NN is a bit more complex than the algorithms used in challenge 1. As mentioned in the crash course an NN exists of multiple layers of which each can be of a different type.\n",
    "\n",
    "We can build up the NN using Keras' sequential model.\n",
    "\n",
    "The network blow uses standard Dense layers and ReLu activation functions. When you feel adventurous you can change these but for this exercise, we advise keeping those set. The first number in each layer defines the number of neurons in the layer and with that the limit of the amount of information that layer can pass to the next. The first layer is called the input layer, here you will need to define the shape of data it should be expecting. Based on this it can determine how many incoming connections each neuron will need. The Last Dense layer should compress the influx of data to the number of classes that exist, therefore the number of neurons should equal the number of classes. In the case of classification, the activation function should determine the choice your model is making. You can choose from several activation functions or even create your own, but when doing classification SoftMax is generally used.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wVaqLcfbnRn4"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "def define_model(input_shape, num_classes):\n",
    "    # Build the architecture\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            keras.layers.Dense(32, activation=\"relu\", input_shape=input_shape),\n",
    "            keras.layers.Dense(16, activation=\"relu\"),\n",
    "            keras.layers.Dense(10, activation=\"relu\"),\n",
    "            keras.layers.Dense(num_classes, activation=\"softmax\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XoZA3DeF3EC9"
   },
   "source": [
    "### Training the network\n",
    "When training a model we need to define the number of epochs it will run for. Furthermore, we need an optimizer, you can use a classic SDG optimizer but here we chose Adam which is similar but has an adaptive learning rate, so you don't need to choose one. Finally, we select a loss function that determines how well the NN is performing. For classification generally Categorical Crossentropy is used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EhhKfVzQn29Q",
    "outputId": "63d363ce-06bf-42d8-975c-3c8da9fb66ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100, 32)           160       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100, 16)           528       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100, 10)           170       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100, 3)            33        \n",
      "=================================================================\n",
      "Total params: 891\n",
      "Trainable params: 891\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/150\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 100, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 4), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 4).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 100, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 4), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 4).\n",
      "4/4 [==============================] - 3s 5ms/step - loss: 1.0518 - accuracy: 0.4000\n",
      "Epoch 2/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0046 - accuracy: 0.3700\n",
      "Epoch 3/150\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9789 - accuracy: 0.3500\n",
      "Epoch 4/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.9673 - accuracy: 0.3500\n",
      "Epoch 5/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.9460 - accuracy: 0.4900\n",
      "Epoch 6/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.9251 - accuracy: 0.6100\n",
      "Epoch 7/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.9052 - accuracy: 0.6600\n",
      "Epoch 8/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8842 - accuracy: 0.6600\n",
      "Epoch 9/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8591 - accuracy: 0.6600\n",
      "Epoch 10/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8357 - accuracy: 0.6600\n",
      "Epoch 11/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8085 - accuracy: 0.6600\n",
      "Epoch 12/150\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7815 - accuracy: 0.7600\n",
      "Epoch 13/150\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7585 - accuracy: 0.8500\n",
      "Epoch 14/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7354 - accuracy: 0.8300\n",
      "Epoch 15/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7139 - accuracy: 0.7900\n",
      "Epoch 16/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6923 - accuracy: 0.8800\n",
      "Epoch 17/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6702 - accuracy: 0.9700\n",
      "Epoch 18/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6489 - accuracy: 0.9500\n",
      "Epoch 19/150\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6300 - accuracy: 0.9800\n",
      "Epoch 20/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6102 - accuracy: 0.9600\n",
      "Epoch 21/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5913 - accuracy: 0.9300\n",
      "Epoch 22/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5748 - accuracy: 0.9200\n",
      "Epoch 23/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5573 - accuracy: 0.8700\n",
      "Epoch 24/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5413 - accuracy: 0.8700\n",
      "Epoch 25/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5293 - accuracy: 0.9200\n",
      "Epoch 26/150\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5140 - accuracy: 0.9000\n",
      "Epoch 27/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5035 - accuracy: 0.8300\n",
      "Epoch 28/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4971 - accuracy: 0.7800\n",
      "Epoch 29/150\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4795 - accuracy: 0.8600\n",
      "Epoch 30/150\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4700 - accuracy: 0.9700\n",
      "Epoch 31/150\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4607 - accuracy: 0.9700\n",
      "Epoch 32/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4488 - accuracy: 0.9700\n",
      "Epoch 33/150\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4371 - accuracy: 0.9400\n",
      "Epoch 34/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4305 - accuracy: 0.8900\n",
      "Epoch 35/150\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4200 - accuracy: 0.9100\n",
      "Epoch 36/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4101 - accuracy: 0.9400\n",
      "Epoch 37/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4036 - accuracy: 0.9400\n",
      "Epoch 38/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3917 - accuracy: 0.9400\n",
      "Epoch 39/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3882 - accuracy: 0.9800\n",
      "Epoch 40/150\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3798 - accuracy: 0.9600\n",
      "Epoch 41/150\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3678 - accuracy: 0.9600\n",
      "Epoch 42/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3666 - accuracy: 0.9300\n",
      "Epoch 43/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3537 - accuracy: 0.9600\n",
      "Epoch 44/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3574 - accuracy: 0.9600\n",
      "Epoch 45/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3639 - accuracy: 0.9300\n",
      "Epoch 46/150\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3378 - accuracy: 0.9800\n",
      "Epoch 47/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3341 - accuracy: 0.9400\n",
      "Epoch 48/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3337 - accuracy: 0.9300\n",
      "Epoch 49/150\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3143 - accuracy: 0.9700\n",
      "Epoch 50/150\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3120 - accuracy: 0.9800\n",
      "Epoch 51/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3026 - accuracy: 0.9700\n",
      "Epoch 52/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2960 - accuracy: 0.9600\n",
      "Epoch 53/150\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2968 - accuracy: 0.9400\n",
      "Epoch 54/150\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2890 - accuracy: 0.9400\n",
      "Epoch 55/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2699 - accuracy: 0.9600\n",
      "Epoch 56/150\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2618 - accuracy: 0.9700\n",
      "Epoch 57/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2656 - accuracy: 0.9600\n",
      "Epoch 58/150\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2511 - accuracy: 0.9800\n",
      "Epoch 59/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2533 - accuracy: 0.9500\n",
      "Epoch 60/150\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2446 - accuracy: 0.9400\n",
      "Epoch 61/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2287 - accuracy: 0.9700\n",
      "Epoch 62/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2298 - accuracy: 0.9800\n",
      "Epoch 63/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2218 - accuracy: 0.9800\n",
      "Epoch 64/150\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2232 - accuracy: 0.9700\n",
      "Epoch 65/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2187 - accuracy: 0.9600\n",
      "Epoch 66/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2046 - accuracy: 0.9700\n",
      "Epoch 67/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1979 - accuracy: 0.9700\n",
      "Epoch 68/150\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1968 - accuracy: 0.9800\n",
      "Epoch 69/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1924 - accuracy: 0.9800\n",
      "Epoch 70/150\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1906 - accuracy: 0.9700\n",
      "Epoch 71/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1835 - accuracy: 0.9700\n",
      "Epoch 72/150\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1819 - accuracy: 0.9600\n",
      "Epoch 73/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1783 - accuracy: 0.9700\n",
      "Epoch 74/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1716 - accuracy: 0.9700\n",
      "Epoch 75/150\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1681 - accuracy: 0.9700\n",
      "Epoch 76/150\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1641 - accuracy: 0.9700\n",
      "Epoch 77/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1607 - accuracy: 0.9700\n",
      "Epoch 78/150\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1584 - accuracy: 0.9700\n",
      "Epoch 79/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1529 - accuracy: 0.9800\n",
      "Epoch 80/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1613 - accuracy: 0.9600\n",
      "Epoch 81/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1460 - accuracy: 0.9800\n",
      "Epoch 82/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1584 - accuracy: 0.9600\n",
      "Epoch 83/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1705 - accuracy: 0.9500\n",
      "Epoch 84/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1438 - accuracy: 0.9700\n",
      "Epoch 85/150\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1424 - accuracy: 0.9700\n",
      "Epoch 86/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1439 - accuracy: 0.9700\n",
      "Epoch 87/150\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1360 - accuracy: 0.9700\n",
      "Epoch 88/150\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1327 - accuracy: 0.9700\n",
      "Epoch 89/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1319 - accuracy: 0.9700\n",
      "Epoch 90/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1279 - accuracy: 0.9700\n",
      "Epoch 91/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1257 - accuracy: 0.9700\n",
      "Epoch 92/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1241 - accuracy: 0.9700\n",
      "Epoch 93/150\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1224 - accuracy: 0.9700\n",
      "Epoch 94/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1214 - accuracy: 0.9700\n",
      "Epoch 95/150\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1175 - accuracy: 0.9700\n",
      "Epoch 96/150\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1300 - accuracy: 0.9600\n",
      "Epoch 97/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1174 - accuracy: 0.9800\n",
      "Epoch 98/150\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1267 - accuracy: 0.9600\n",
      "Epoch 99/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1348 - accuracy: 0.9500\n",
      "Epoch 100/150\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1118 - accuracy: 0.9700\n",
      "Epoch 101/150\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1224 - accuracy: 0.9600\n",
      "Epoch 102/150\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1096 - accuracy: 0.9800\n",
      "Epoch 103/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1107 - accuracy: 0.9700\n",
      "Epoch 104/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1184 - accuracy: 0.9700\n",
      "Epoch 105/150\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1107 - accuracy: 0.9700\n",
      "Epoch 106/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1077 - accuracy: 0.9700\n",
      "Epoch 107/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1091 - accuracy: 0.9700\n",
      "Epoch 108/150\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1024 - accuracy: 0.9800\n",
      "Epoch 109/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1017 - accuracy: 0.9800\n",
      "Epoch 110/150\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1002 - accuracy: 0.9800\n",
      "Epoch 111/150\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1056 - accuracy: 0.9700\n",
      "Epoch 112/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1000 - accuracy: 0.9800\n",
      "Epoch 113/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1007 - accuracy: 0.9700\n",
      "Epoch 114/150\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1001 - accuracy: 0.9700\n",
      "Epoch 115/150\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0985 - accuracy: 0.9700\n",
      "Epoch 116/150\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0962 - accuracy: 0.9600\n",
      "Epoch 117/150\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0966 - accuracy: 0.9700\n",
      "Epoch 118/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0973 - accuracy: 0.9700\n",
      "Epoch 119/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0914 - accuracy: 0.9800\n",
      "Epoch 120/150\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0975 - accuracy: 0.9700\n",
      "Epoch 121/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0974 - accuracy: 0.9700\n",
      "Epoch 122/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0882 - accuracy: 0.9900\n",
      "Epoch 123/150\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0962 - accuracy: 0.9700\n",
      "Epoch 124/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0905 - accuracy: 0.9800\n",
      "Epoch 125/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0929 - accuracy: 0.9700\n",
      "Epoch 126/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0917 - accuracy: 0.9700\n",
      "Epoch 127/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0857 - accuracy: 0.9800\n",
      "Epoch 128/150\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0882 - accuracy: 0.9800\n",
      "Epoch 129/150\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0862 - accuracy: 0.9800\n",
      "Epoch 130/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0854 - accuracy: 0.9900\n",
      "Epoch 131/150\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0874 - accuracy: 0.9700\n",
      "Epoch 132/150\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0843 - accuracy: 0.9800\n",
      "Epoch 133/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0840 - accuracy: 0.9800\n",
      "Epoch 134/150\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0844 - accuracy: 0.9800\n",
      "Epoch 135/150\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0879 - accuracy: 0.9700\n",
      "Epoch 136/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0845 - accuracy: 0.9800\n",
      "Epoch 137/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0832 - accuracy: 0.9700\n",
      "Epoch 138/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0844 - accuracy: 0.9700\n",
      "Epoch 139/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0823 - accuracy: 0.9800\n",
      "Epoch 140/150\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0835 - accuracy: 0.9800\n",
      "Epoch 141/150\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0928 - accuracy: 0.9600\n",
      "Epoch 142/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0863 - accuracy: 0.9600\n",
      "Epoch 143/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0790 - accuracy: 0.9800\n",
      "Epoch 144/150\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0825 - accuracy: 0.9700\n",
      "Epoch 145/150\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0791 - accuracy: 0.9800\n",
      "Epoch 146/150\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0823 - accuracy: 0.9700\n",
      "Epoch 147/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0853 - accuracy: 0.9600\n",
      "Epoch 148/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0781 - accuracy: 0.9700\n",
      "Epoch 149/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0791 - accuracy: 0.9700\n",
      "Epoch 150/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0790 - accuracy: 0.9700\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 150\n",
    "input_shape = X_train.shape\n",
    "num_classes = y_train.shape[-1]\n",
    "\n",
    "model = define_model(input_shape, num_classes)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y2ROP0mI4njl"
   },
   "source": [
    "### Metric Scores\n",
    "Finally, we need to determine if our NN has actually learned something by testing it on data it has never seen before, the test set. Below we calculate the loss (categorical cross-entropy) which is a bit hard to interpret. But also the accuracy which can be used in case of classification and is very easy to interpret since it is basically the percentage of cases in the test set it predicted correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UKt-0TZbn3B8",
    "outputId": "ad5ec232-71ac-41a0-802d-ccadf66ad88c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 100, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 4), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 4).\n",
      "Test loss: 0.06666319072246552\n",
      "Test accuracy: 0.9599999785423279\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qwmpWTjG5gog"
   },
   "source": [
    "## **Challenge 2:** Tune the MLP\n",
    "Tune the parameters until you get a test accuracy of 98%. We advise starting with changing the number of layers and the number of neurons in each layer and proceed with changing the number of epochs. You are free to change anything else from the optimizer to the layer types but make sure to save enough time for the next challenge. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u86En6iir7zI"
   },
   "source": [
    "## Convolutional Neural Networks\n",
    "This challenge is going to be a bit more, well... challenging. You are going to process image data and in the end-use Convolutional Neural Networks to process image data. These types of algorithms are designed to use multidimensional data where the spatial relations between the dimensions are relevant or in other words, good with pretty pictures.\n",
    "\n",
    "Today we are going to use the MNIST dataset, probably the most famous dataset in all of AI. It consists of 28x28 pixel pictures of handwritten numbers in black and white images.\n",
    "\n",
    "We are going to use some real Deep Learning here that benefits from GPU acceleration. Luckily Colab can provide us with a free GPU to train the neural networks faster. You can activate GPU acceleration in the Runtime tab: Runtime -> Change runtime type -> Select GPU from the dropdown\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JkKR-08csFI1"
   },
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wEEexzS4YLqh"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aNaXlRm_gl76",
    "outputId": "ccd75677-bcb2-4d0c-e5b2-1558cb8f0a00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 0us/step\n",
      "40960/29515 [=========================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 0s 0us/step\n",
      "26435584/26421880 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "16384/5148 [===============================================================================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 0s 0us/step\n",
      "4431872/4422102 [==============================] - 0s 0us/step\n",
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Download the dataset\n",
    "from keras.datasets import mnist, fashion_mnist\n",
    "#(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "A2iXRbCPgnrD",
    "outputId": "c9abd456-394a-45fb-df79-1660be044218"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# View example digit\n",
    "index = np.random.randint(0,60000)\n",
    "plt.imshow(X_train[index])\n",
    "print(y_train[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P3-9JrJqzC3a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6TMVvSDJzNIc"
   },
   "source": [
    "### Reshaping the data\n",
    "CNNs expect the data to be in a specific shape depending on the number of dimensions. Since we work with image data, we will use 2D CNN layers. The expected shape that would be as follows (number_of_samples, dimention_size_1, dimentionon_size_2, channel). Looking at the X_train. The shape above the first 3 is easy to derive. The number of training samples is 60000 and the images are 28*28 and therefore those would be the two dimension sizes. Channel would basically be the number of spectral wavelengths are in the data. For colored images this would be 3 (r,g,b) for black and white images this would just be 1, and for multispectral satellite images, this could be many more. In this case, we have black and white images, so we end up with the desired X_train shape of (60000,28,28,1). This is not the shape of our data as can be seen above, that would be (60000,28,28). This is because it has the intensity value in the second dimension instead of it being just a coordinate and an extra dimension for the intensity. Luckily we can easily reshape the data to our desired format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UveRpDvhf9uj"
   },
   "outputs": [],
   "source": [
    "# Put it into suitable shape\n",
    "X_train = X_train.reshape(60000,28,28,1)\n",
    "X_test = X_test.reshape(10000,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FuK2gEM_wzPN",
    "outputId": "2754c188-1d7d-47f5-a83b-fe3e6686a426"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "# Convert labels to onehot (just like in previous example)\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "lb = LabelBinarizer()\n",
    "lb.fit(y_train)\n",
    "y_train = lb.transform(y_train)\n",
    "y_test = lb.transform(y_test)\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GRGtw9743JZ_"
   },
   "source": [
    "### Architecture\n",
    "Now for the architecture\n",
    "\n",
    "- This time we defined the input in a separate Input Layer, which results in exactly the same as when you define input_shape in the first layer.\n",
    "- Then we do a single Convolutional layer\n",
    "- The last layer should stay a Dense layer with the number of classes for neurons just like with the previous. However, we can not just push 2D data into a 1D Dense layer therefore we need to Flatten the data first using a Flatten layer.\n",
    "\n",
    "\n",
    "Configuring the Conv2D layers will require some fiddling, here is the documentation:\n",
    "https://keras.io/api/layers/convolution_layers/convolution2d/\n",
    "<br><br>\n",
    "You should at least define a **filter size**, to keep it simple this number determines the amount of information that will be collected per output \"pixel\" in the output. So a higher number means more space for information but also longer compute times and larger model size. \n",
    "<br><br>\n",
    "Then you should also define a **kernel size** (also known as window) Which basically determines how much information is condensed into an output \"pixel\". This means that larger kernels result in a larger segment of the image will be cramped into a smaller resulting image. So here larger means less information pushed to the next layer. \n",
    "\n",
    "**Warning:** When adding Conv layers and changing kernel sizes you impact the shape of de \"image\" that is passed to the next layers, often making it smaller. This means that when you stack too many layers and/or use large kernel sizes, the image at some point will become smaller than 0x0 resulting in a crash. You can simply calculate the effect each propagating layer will have on the image but you can also pay extra attention to the model summary since that will show the resulting image dimensions after each layer.\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nTAKVGm6yqD2"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import (Input, Conv2D, MaxPooling2D, Flatten, \n",
    "                                     Dense, Dropout, BatchNormalization, Activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n7hnzeQAf9uj"
   },
   "outputs": [],
   "source": [
    "def define_cnn(input_shape, num_classes):\n",
    "    # Build the architecture\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    # first CONV => RELU => CONV => RELU => POOL layer set\n",
    "    model.add(Conv2D(32, (3, 3), padding=\"same\",\n",
    "        input_shape=input_shape))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(32, (3, 3), padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    # second CONV => RELU => CONV => RELU => POOL layer set\n",
    "    model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    # first (and only) set of FC => RELU layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    # softmax classifier\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "\n",
    "    model.summary()\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r2XIOGBE240D"
   },
   "source": [
    "### Training the network\n",
    "For the optimizer we will use classic Stochastic Gradient Descent. There exist more advanced optimizers like Adam, but we will skip those for now. The loss defines how we punish the network for a mistake. Without going into the details Categorical Crossentropy is generally used with classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DWfU_UfNyo0m",
    "outputId": "cd99ad72-838f-4923-b701-8728239b1be6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               1606144   \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,679,082\n",
      "Trainable params: 1,677,674\n",
      "Non-trainable params: 1,408\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 64s 18ms/step - loss: 0.4457 - accuracy: 0.8455 - val_loss: 0.2883 - val_accuracy: 0.9025\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 0.2992 - accuracy: 0.8940 - val_loss: 0.2477 - val_accuracy: 0.9121\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 35s 18ms/step - loss: 0.2671 - accuracy: 0.9034 - val_loss: 0.2338 - val_accuracy: 0.9181\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 35s 18ms/step - loss: 0.2446 - accuracy: 0.9124 - val_loss: 0.2608 - val_accuracy: 0.9061\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 35s 18ms/step - loss: 0.2346 - accuracy: 0.9156 - val_loss: 0.2197 - val_accuracy: 0.9229\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 34s 18ms/step - loss: 0.2110 - accuracy: 0.9235 - val_loss: 0.2262 - val_accuracy: 0.9168\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 34s 18ms/step - loss: 0.2030 - accuracy: 0.9264 - val_loss: 0.2128 - val_accuracy: 0.9276\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 35s 19ms/step - loss: 0.1875 - accuracy: 0.9311 - val_loss: 0.1943 - val_accuracy: 0.9326\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 35s 19ms/step - loss: 0.1792 - accuracy: 0.9351 - val_loss: 0.1943 - val_accuracy: 0.9315\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 35s 19ms/step - loss: 0.1673 - accuracy: 0.9390 - val_loss: 0.1932 - val_accuracy: 0.9337\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "batch_size = 32\n",
    "input_shape = X_train.shape[1:]\n",
    "num_classes = y_train.shape[-1]\n",
    "\n",
    "model = define_cnn(input_shape, num_classes)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# Train and test\n",
    "H = model.fit(X_train, y_train, batch_size=batch_size, epochs=num_epochs, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6HpDQN0tyLFt",
    "outputId": "9c1505f3-41a6-4411-d592-f370cba182c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.19323410093784332\n",
      "Test accuracy: 0.9337000250816345\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JYksOsW1yo0m"
   },
   "source": [
    "## **Challenge 2:** Tune the CNN\n",
    "2.1: Add convolutional layers, change kernel and filter sizes to get to a 98% accuracy on the test dataset\n",
    "\n",
    "2.2: Go back to the data loader and change the MNIST loader to the Fashion MNIST loader \"fashion_mnist.load_data()\". Tune the parameters until you reach an accuracy of 87% on the test dataset.\n",
    "\n",
    "2.3 (Advanced): Include max-pooling, dropout, and batch normalization layers to reach a test accuracy of 90% on the test set.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vA_9-0km8IYN"
   },
   "source": [
    "## **Challenge 3 (Extra Advanced):** Forecasting and RNNs\n",
    "Forecasting is a special branch of machine learning regression problems where you try to predict how the trend will proceed. Often this is still most successful with more classical statistical methods like variants on the Moving Average algorithm. These types of algorithms often require a better understanding of the dataset since its parameters really make or break the model. Note that for the following challenges no solutions are available and therefore no support will be provided.\n",
    "\n",
    "3.1 Facebook has created an algorithm called Prophet which is based on statistical methods which makes it a bit easier to create such models and often outperforms other algorithms. Install and deploy Prophet on the dataset below.\n",
    "\n",
    "3.2 Rolling SARIMAX is one of the most powerful statistical forecasting methods. While the algorithm itself is not too complex it can be hard to choose the correct parameters. Deploy a Rolling SARIMAX algorithm on the dataset below.\n",
    "\n",
    "3.3 RNNs are very well suited for forecasting use cases, more specifically the LSTM and GRU types of RNNs often work well (not perse better than the above methods). RNNs will come up themselves with the parameters you had to define in previous algorithms, however that does not make them easier to deploy. Use an LSTM to forecast on the dataset below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "lvMB0-8Vyo0k",
    "outputId": "dbdf791c-2c72-44a3-d6ca-6a228a7a4362"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/jbrownlee/Datasets/master/airline-passengers.csv', usecols=[1], engine='python')\n",
    "plt.plot(df)\n",
    "plt.show()\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vj4RStrdSxMz"
   },
   "outputs": [],
   "source": [
    "test_steps = 36\n",
    "train, test = df[:test_steps], df[-test_steps:]"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Week 1 - AI Models and Data Types - Answers",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
